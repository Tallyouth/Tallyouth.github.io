<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="learning">
    

    <!--Author-->
    
        <meta name="author" content="yhb">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="docker 核心技术与实现原理"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="learning" />
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="learning"/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>docker 核心技术与实现原理 - learning</title>

    <!-- Tachyons Core CSS -->
    <link rel="stylesheet" href="https://unpkg.com/tachyons/css/tachyons.min.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Google Analytics -->
    


<meta name="generator" content="Hexo 5.0.2"></head>


<body>

<!-- Main Content -->
<!-- Banner -->
<!-- Banner -->
<div class="w-100 bg-1 ph5-ns ph3 text-light">
    
    <nav class="db dt-l w-100 mw8 center border-box pv3">
        <a class="db dtc-l v-mid link dim w-100 w-25-l tc tl-l mb2 mb0-l white" href="/" title="learning">
            <img src="http://www.codeblocq.com/assets/projects/hexo-theme-anodyne/assets/anodyne.svg" class="dib h3" alt="learning">
        </a>
        <div class="db dtc-l v-mid w-100 w-75-l tc tr-l">
            
                <a class="link dim f6 f5-l dib mr3 mr4-l white" 
                    href="/" 
                    title="home">
                    home
                </a>
            
                <a class="link dim f6 f5-l dib mr3 mr4-l white" 
                    href="/tags" 
                    title="Tags">
                    Tags
                </a>
            
                <a class="link dim f6 f5-l dib mr3 mr4-l white" 
                    href="/archives" 
                    title="Archives">
                    Archives
                </a>
            
        </div>
    </nav>

    <!-- Title -->
    <div class="w-100 mw8 center vh-40 dt">
        <div class="dtc v-mid white">
            <h1 class="f1-l f2-m tc tc-m tl-ns">docker 核心技术与实现原理</h1>
            <p class="f4 fw3 pab-100px tc tc-m tl-ns">2020-09-02</p>
        </div>
    </div>

    <!-- Icon -->
    <div class="relative w-100 mw8 center white dn dn-m db-ns">
        <i class="header-icon fa fa-thumbs-up"></i>
    </div>
</div>

<!-- Content -->
<div class="w-100 ph2 ph4-m ph5-l mv5 mv6-l">
    <div class="content">
        <div class="mw8 center">
            <div class="cf">
                <div class="fl w-100 w-70-l mw7 left fw3 lh-copy pr4-ns pr0-m post-content">
                    <!-- Tags Vertical -->
                    
                        <div class="tags-container-vertical">
                            <div class="tags-sub-container">
                                <a class="fw3 ph1 dib" href="/tags/docker/">#docker</a> <a class="fw3 ph1 dib" href="/tags/虚拟机/">#虚拟机</a>
                            </div>
                        </div>
                    

                    <!-- Main Post Content -->
                    <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>一直使用docker，极大的便利了程序的部署，不用为环境发愁。但是一直没有了解docker是如何实现的，底层原理是什么，为什么可以和宿主机分开，为什么可以有自己独立的端口，他和虚拟机有什么区别</p>
<p>看了这篇文章才懂 <a target="_blank" rel="noopener" href="http://dockone.io/article/2941">文章链接</a></p>
<h3 id="和虚拟机的区别是什么"><a href="#和虚拟机的区别是什么" class="headerlink" title="和虚拟机的区别是什么"></a>和虚拟机的区别是什么</h3><ul>
<li>Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。</li>
<li>Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。</li>
<li>虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。（秒级）</li>
<li>由于没有臃肿的从操作系统,Docker可以节省大量的磁盘空间以及其他系统资源。</li>
<li>虚拟机更擅长于彻底隔离整个运行环境，Docker通常用于隔离不同的应用，例如前端，后端以及数据库。本质上来说docker 属于进程之间的隔离，虚拟机可实现系统级别隔离。</li>
<li>安全性： docker 的安全性也更弱。Docker 的租户 root 和宿主机 root 等同，一旦容器内的用户从普通用户权限提升为 root 权限，它就直接具备了宿主机的 root 权限，进而可进行无限制的操作。虚拟机租户 root 权限和宿主机的 root 虚拟机权限是分离的，并且虚拟机利用如 Intel 的 VT-d 和 VT-x 的 ring-1 硬件隔离技术，这种隔离技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离，这使得容器容易受到攻击。</li>
</ul>
<h3 id="Docker-核心技术与实现原理"><a href="#Docker-核心技术与实现原理" class="headerlink" title="Docker 核心技术与实现原理"></a>Docker 核心技术与实现原理</h3><h4 id="Namespaces"><a href="#Namespaces" class="headerlink" title="Namespaces"></a>Namespaces</h4><ul>
<li><p>命名空间（namespaces）是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。在这种情况下，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这也是我们不想看到的，而 Docker 其实就通过 Linux 的 Namespaces 对不同的容器实现了隔离。<br>Linux Namespaces机制提供一种资源隔离方案。PID,IPC,Network等系统资源不再是全局性的，而是属于特定的Namespace。每个Namespace里面的资源对其他Namespace都是透明的。要创建新的Namespace，只需要在调用clone时指定相应的flag。Linux Namespaces机制为实现基于容器的虚拟化技术提供了很好的基础，LXC（Linux containers）就是利用这一特性实现了资源的隔离。不同container内的进程属于不同的Namespace，彼此透明，互不干扰。Linux 的命名空间机制提供了以下七种不同的命名空间(flag)，包括 </p>
<p>  <a href="#">CLONE_NEWCGROUP</a></p>
<p>  <a href="#clone-flag2">CLONE_NEWIPC</a></p>
<p>  <a href="#clone-flag4">CLONE_NEWNET</a></p>
<p>  <a href="#clone-flag3">CLONE_NEWNS</a></p>
<p>  <a href="#clone-flag1">CLONE_NEWPID</a></p>
<p>  <a href="#">CLONE_NEWUSER</a></p>
<p>  <a href="#clone-flag5">CLONE_NEWUTS</a></p>
<table>
<thead>
<tr>
<th>flag标记位</th>
<th>功能</th>
<th>隔离的资源</th>
<th>Linux内核版本支持</th>
</tr>
</thead>
<tbody><tr>
<td>CLONE_NEWIPC</td>
<td>在新的 IPC namespace启动新进程</td>
<td>进程间通信，包括信号量、消息队列和共享内存</td>
<td>since 2.6.19</td>
</tr>
<tr>
<td>CLONE_NEWNET</td>
<td>在新的network namespace启动新进程</td>
<td>网络设备、网络栈、端口</td>
<td>since 2.6.24</td>
</tr>
<tr>
<td>CLONE_NEWNS</td>
<td>在新的mount namespace启动新进程</td>
<td>挂载点（文件系统）</td>
<td>since 2.6.19</td>
</tr>
<tr>
<td>CLONE_NEWPID</td>
<td>在新的PID namespace启动新进程</td>
<td>进程编号（新的进程树）</td>
<td>since 2.6.24</td>
</tr>
<tr>
<td>CLONE_NEWUSER</td>
<td>在新的user namespace启动新进程</td>
<td>用户和用户组</td>
<td>在2.6.23引入，在3.5和3.8有更新</td>
</tr>
<tr>
<td>CLONE_NEWUTS</td>
<td>在新的UTS namespace启动新进程</td>
<td>主机名和域</td>
<td>since 2.6.19</td>
</tr>
<tr>
<td>CLONE_NEWCGROUP</td>
<td>在新的cgroup namespace启动新进程</td>
<td>CPU、内存、磁盘读写等</td>
<td>since 4.6</td>
</tr>
</tbody></table>
</li>
</ul>
<p>通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。</p>
<h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><ul>
<li><p>进程是 Linux 以及现在操作系统中非常重要的概念，它表示一个正在执行的程序，也是在现代分时系统中的一个任务单元。在每一个 *nix 的操作系统上，我们都能够通过 ps 命令打印出当前操作系统中正在执行的进程，比如在 Ubuntu 上，使用该命令就能得到以下的结果：</p>
<pre><code>  $ ps -ef
  UID        PID  PPID  C STIME TTY          TIME CMD
  root         1     0  0 Apr08 ?        00:00:09 /sbin/init
  root         2     0  0 Apr08 ?        00:00:00 [kthreadd]
  root         3     2  0 Apr08 ?        00:00:05 [ksoftirqd/0]
  root         5     2  0 Apr08 ?        00:00:00 [kworker/0:0H]
  root         7     2  0 Apr08 ?        00:07:10 [rcu_sched]
  root        39     2  0 Apr08 ?        00:00:00 [migration/0]
  root        40     2  0 Apr08 ?        00:01:54 [watchdog/0]
  ...</code></pre>
<p>  当前机器上有很多的进程正在执行，在上述进程中有两个非常特殊，一个是 pid 为 1 的 <a href="#sbin-init">/sbin/init</a> 进程，另一个是 pid 为 2 的 <a href="#kthreadd">kthreadd</a> 进程，这两个进程都是被 Linux 中的上帝进程 <a href="#idle">idle</a> 创建出来的，其中前者负责执行内核的一部分初始化工作和系统配置，也会创建一些类似 <a href="#getty">getty</a> 的注册进程，而后者负责管理和调度其他的内核进程。<br><img src="http://ww1.sinaimg.cn/large/005Seyywly1gidb44br0qj30xc0iwwfc.jpg" alt="undefined"></p>
<p>  如果我们在当前的 Linux 操作系统下运行一个新的 Docker 容器，并通过 exec 进入其内部的 bash 并打印其中的全部进程，我们会得到以下的结果：</p>
<pre><code>  root@iZ255w13cy6Z:~# docker run -it -d ubuntu
  b809a2eb3630e64c581561b08ac46154878ff1c61c6519848b4a29d412215e79
  root@iZ255w13cy6Z:~# docker exec -it b809a2eb3630 /bin/bash
  root@b809a2eb3630:/# ps -ef
  UID        PID  PPID  C STIME TTY          TIME CMD
  root         1     0  0 15:42 pts/0    00:00:00 /bin/bash
  root         9     0  0 15:42 pts/1    00:00:00 /bin/bash
  root        17     9  0 15:43 pts/1    00:00:00 ps -ef</code></pre>
<p>  在新的容器内部执行 ps 命令打印出了非常干净的进程列表，只有包含当前 ps -ef 在内的三个进程，在宿主机器上的几十个进程都已经消失不见了。</p>
<p>  当前的 Docker 容器成功将容器内的进程与宿主机器中的进程隔离，如果我们在宿主机器上打印当前的全部进程时，会得到下面三条与 Docker 相关的结果：</p>
<pre><code>  UID        PID  PPID  C STIME TTY          TIME CMD
  root     29407     1  0 Nov16 ?        00:08:38 /usr/bin/dockerd --raw-logs
  root      1554 29407  0 Nov19 ?        00:03:28 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc
  root      5006  1554  0 08:38 ?        00:00:00 docker-containerd-shim b809a2eb3630e64c5815</code></pre>
<p>  在当前的宿主机器上，可能就存在由上述的不同进程构成的进程树：</p>
<p>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1gidimx92d4j30xc0eg0ts.jpg" alt="undefined"></p>
<p>  这就是在使用 clone(2) 创建新进程时传入 CLONE_NEWPID 实现的，也就是使用 Linux 的命名空间实现进程的隔离，Docker 容器内部的任意进程都对宿主机器的进程一无所知。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">containerRouter.postContainersStart</span><br><span class="line">└── daemon.ContainerStart</span><br><span class="line">└── daemon.createSpec</span><br><span class="line">    └── setNamespaces</span><br><span class="line">        └── setNamespace</span><br></pre></td></tr></table></figure>
<p>Docker 的容器就是使用上述技术实现与宿主机器的进程隔离，当我们每次运行 docker run 或者 docker start 时，都会在下面的方法中创建一个用于设置进程间隔离的 Spec：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">func (daemon *Daemon) createSpec(c *container.Container) (*specs.Spec, error) &#123;</span><br><span class="line">s :&#x3D; oci.DefaultSpec()</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; ...</span><br><span class="line">if err :&#x3D; setNamespaces(daemon, &amp;s, c); err !&#x3D; nil &#123;</span><br><span class="line">    return nil, fmt.Errorf(&quot;linux spec namespaces: %v&quot;, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return &amp;s, nil</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>在 setNamespaces 方法中不仅会设置进程相关的命名空间，还会设置与用户、网络、IPC 以及 UTS 相关的命名空间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">func setNamespaces(daemon *Daemon, s *specs.Spec, c *container.Container) error &#123;</span><br><span class="line">&#x2F;&#x2F; user</span><br><span class="line">&#x2F;&#x2F; network</span><br><span class="line">&#x2F;&#x2F; ipc</span><br><span class="line">&#x2F;&#x2F; uts</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; pid</span><br><span class="line">if c.HostConfig.PidMode.IsContainer() &#123;</span><br><span class="line">    ns :&#x3D; specs.LinuxNamespace&#123;Type: &quot;pid&quot;&#125;</span><br><span class="line">    pc, err :&#x3D; daemon.getPidContainer(c)</span><br><span class="line">    if err !&#x3D; nil &#123;</span><br><span class="line">        return err</span><br><span class="line">    &#125;</span><br><span class="line">    ns.Path &#x3D; fmt.Sprintf(&quot;&#x2F;proc&#x2F;%d&#x2F;ns&#x2F;pid&quot;, pc.State.GetPID())</span><br><span class="line">    setNamespace(s, ns)</span><br><span class="line">&#125; else if c.HostConfig.PidMode.IsHost() &#123;</span><br><span class="line">    oci.RemoveNamespace(s, specs.LinuxNamespaceType(&quot;pid&quot;))</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    ns :&#x3D; specs.LinuxNamespace&#123;Type: &quot;pid&quot;&#125;</span><br><span class="line">    setNamespace(s, ns)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">return nil</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>所有命名空间相关的设置 Spec 最后都会作为 Create 函数的入参在创建新的容器时进行设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">daemon.containerd.Create(context.Background(), container.ID, spec, createOptions)</span><br></pre></td></tr></table></figure>
<p>所有与命名空间的相关的设置都是在上述的两个函数中完成的，Docker 通过命名空间成功完成了与宿主机进程和网络的隔离。</p>
</li>
</ul>
<h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h4><ul>
<li><p>如果 Docker 的容器通过 Linux 的命名空间完成了与宿主机进程的网络隔离，但是却没有办法通过宿主机的网络与整个互联网相连，就会产生很多限制，所以 Docker 虽然可以通过命名空间创建一个隔离的网络环境，但是 Docker 中的服务仍然需要与外界相连才能发挥作用。<br>每一个使用 docker run 启动的容器其实都具有单独的网络命名空间，Docker 为我们提供了四种不同的网络模式，Host、Container、None 和 Bridge 模式。<br><img src="http://ww1.sinaimg.cn/large/005Seyywly1gidjupewgnj30xc08wdga.jpg" alt="undefined"></p>
<p>  在这一部分，我们将介绍 Docker 默认的网络设置模式：网桥模式。在这种模式下，除了分配隔离的网络命名空间之外，Docker 还会为所有的容器设置 IP 地址。当 Docker 服务器在主机上启动之后会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连。<br><img src="http://ww1.sinaimg.cn/large/005Seyywly1gidjvknip3j30xc0jqq3j.jpg" alt="undefined"></p>
<p>  在默认情况下，每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在创建的容器中，另一个会加入到宿主机名为 docker0 网桥中。我们可以使用如下的命令来查看当前网桥的接口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ brctl show</span><br><span class="line">bridge name bridge id       STP enabled interfaces</span><br><span class="line">docker0     8000.0242a6654980   no      veth3e84d4f</span><br><span class="line">                                    veth9953b75</span><br></pre></td></tr></table></figure>
<p>docker0 会为每一个容器分配一个新的 IP 地址并将 docker0 的 IP 地址设置为默认的网关。网桥 docker0 通过 iptables 中的配置与宿主机器上的网卡相连，所有符合条件的请求都会通过 iptables 转发到 docker0 并由网桥分发给对应的机器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ iptables -t nat -L</span><br><span class="line">Chain PREROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">DOCKER     all  --  anywhere             anywhere             ADDRTYPE match dst-type LOCAL</span><br><span class="line"></span><br><span class="line">Chain DOCKER (2 references)</span><br><span class="line">target     prot opt source               destination</span><br><span class="line">RETURN     all  --  anywhere             anywhere</span><br></pre></td></tr></table></figure>
<p>我们在当前的机器上使用 docker run -d -p 6379:6379 redis 命令启动了一个新的 Redis 容器，在这之后我们再查看当前 iptables 的 NAT 配置就会看到在 DOCKER 的链中出现了一条新的规则：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DNAT       tcp  --  anywhere             anywhere             tcp dpt:6379 to:192.168.0.4:6379</span><br></pre></td></tr></table></figure>
<p>上述规则会将从任意源发送到当前机器 6379 端口的 TCP 包转发到 192.168.0.4:6379 所在的地址上。<br>这个地址其实也是 Docker 为 Redis 服务分配的 IP 地址，如果我们在当前机器上直接 ping 这个 IP 地址就会发现它是可以访问到的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ ping 192.168.0.4</span><br><span class="line">PING 192.168.0.4 (192.168.0.4) 56(84) bytes of data.</span><br><span class="line">64 bytes from 192.168.0.4: icmp_seq&#x3D;1 ttl&#x3D;64 time&#x3D;0.069 ms</span><br><span class="line">64 bytes from 192.168.0.4: icmp_seq&#x3D;2 ttl&#x3D;64 time&#x3D;0.043 ms</span><br><span class="line">^C</span><br><span class="line">--- 192.168.0.4 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 999ms</span><br><span class="line">rtt min&#x2F;avg&#x2F;max&#x2F;mdev &#x3D; 0.043&#x2F;0.056&#x2F;0.069&#x2F;0.013 ms</span><br></pre></td></tr></table></figure>
<p>从上述的一系列现象，我们就可以推测出 Docker 是如何将容器的内部的端口暴露出来并对数据包进行转发的了；当有 Docker 的容器需要将服务暴露给宿主机器，就会为容器分配一个 IP 地址，同时向 iptables 中追加一条新的规则。<br><img src="http://ww1.sinaimg.cn/large/005Seyywly1gidk5rmnj2j30xc0m80tf.jpg" alt="undefined"><br>当我们使用 redis-cli 在宿主机器的命令行中访问 127.0.0.1:6379 的地址时，经过 iptables 的 NAT PREROUTING 将 ip 地址定向到了 192.168.0.4，重定向过的数据包就可以通过 iptables 中的 FILTER 配置，最终在 NAT POSTROUTING 阶段将 ip 地址伪装成 127.0.0.1，到这里虽然从外面看起来我们请求的是 127.0.0.1:6379，但是实际上请求的已经是 Docker 容器暴露出的端口了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli -h 127.0.0.1 -p 6379 ping</span><br><span class="line">PONG</span><br></pre></td></tr></table></figure>
<p>Docker 通过 Linux 的命名空间实现了网络的隔离，又通过 iptables 进行数据包转发，让 Docker 容器能够优雅地为宿主机器或者其他容器提供服务。</p>
</li>
</ul>
<h4 id="Libnetwork"><a href="#Libnetwork" class="headerlink" title="Libnetwork"></a>Libnetwork</h4><ul>
<li>整个网络部分的功能都是通过 Docker 拆分出来的 libnetwork 实现的，它提供了一个连接不同容器的实现，同时也能够为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型。<br>libnetwork 中最重要的概念，容器网络模型由以下的几个主要组件组成，分别是 Sandbox、Endpoint 和 Network：<br><img src="http://ww1.sinaimg.cn/large/005Seyywly1gieeqfra0oj30xc0ci0t4.jpg" alt="undefined"><br>在容器网络模型中，每一个容器内部都包含一个 Sandbox，其中存储着当前容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个 Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡 veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux 网桥或者 VLAN。</li>
</ul>
<h4 id="挂载点"><a href="#挂载点" class="headerlink" title="挂载点"></a>挂载点</h4><ul>
<li><p>虽然我们已经通过 Linux 的命名空间解决了进程和网络隔离的问题，在 Docker 进程中我们已经没有办法访问宿主机器上的其他进程并且限制了网络的访问，但是 Docker 容器中的进程仍然能够访问或者修改宿主机器上的其他目录，这是我们不希望看到的。</p>
<p>  在新的进程中创建隔离的挂载点命名空间需要在 clone 函数中传入 CLONE_NEWNS，这样子进程就能得到父进程挂载点的拷贝，如果不传入这个参数子进程对文件系统的读写都会同步回父进程以及整个主机的文件系统。</p>
<p>  如果一个容器需要启动，那么它一定需要提供一个根文件系统（rootfs），容器需要使用这个文件系统来创建一个新的进程，所有二进制的执行都必须在这个根文件系统中。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1gieeuyg5zgj30xc0d2q3a.jpg" alt="undefined"></p>
<p>  想要正常启动一个容器就需要在 rootfs 中挂载以上的几个特定的目录，除了上述的几个目录需要挂载之外我们还需要建立一些符号链接保证系统 IO 不会出现问题。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1giefbkqrptj30xc0e674z.jpg" alt="undefined"></p>
<p>  为了保证当前的容器进程没有办法访问宿主机器上其他目录，我们在这里还需要通过 libcotainer 提供的 pivor_root 或者 chroot 函数改变进程能够访问个文件目录的根节点。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; pivor_root</span><br><span class="line">put_old &#x3D; mkdir(...);</span><br><span class="line">pivot_root(rootfs, put_old);</span><br><span class="line">chdir(&quot;&#x2F;&quot;);</span><br><span class="line">unmount(put_old, MS_DETACH);</span><br><span class="line">rmdir(put_old);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; chroot</span><br><span class="line">mount(rootfs, &quot;&#x2F;&quot;, NULL, MS_MOVE, NULL);</span><br><span class="line">chroot(&quot;.&quot;);</span><br><span class="line">chdir(&quot;&#x2F;&quot;);</span><br></pre></td></tr></table></figure>
<p>  到这里我们就将容器需要的目录挂载到了容器中，同时也禁止当前的容器进程访问宿主机器上的其他目录，保证了不同文件系统的隔离。</p>
<blockquote>
<p>这一部分的内容是作者在 libcontainer 中的 <a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/blob/master/libcontainer/SPEC.md">SPEC.md</a> 文件中找到的，其中包含了 Docker 使用的文件系统的说明，对于 Docker 是否真的使用 chroot 来确保当前的进程无法访问宿主机器的目录，作者其实也没有确切的答案.</p>
</blockquote>
</li>
</ul>
<h4 id="CGroups"><a href="#CGroups" class="headerlink" title="CGroups"></a>CGroups</h4><ul>
<li><p>我们通过 Linux 的命名空间为新创建的进程隔离了文件系统、网络并与宿主机器之间的进程相互隔离，但是命名空间并不能够为我们提供物理资源上的隔离，比如 CPU 或者内存，如果在同一台机器上运行了多个对彼此以及宿主机器一无所知的『容器』，这些容器却共同占用了宿主机器的物理资源。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1giefnxbwf4j30xc0dwq3g.jpg" alt="undefined"></p>
<p>  如果其中的某一个容器正在执行 CPU 密集型的任务，那么就会影响其他容器中任务的性能与执行效率，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了解决进程虚拟资源隔离之后的主要问题，而 Control Groups（简称 CGroups）就是能够隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网络带宽。</p>
<p>  每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1gieforcbl0j30xc0dmmxj.jpg" alt="undefined"></p>
<p>  Linux 的 CGroup 能够为一组进程分配资源，也就是我们在上面提到的 CPU、内存、网络带宽等资源，通过对资源的分配，CGroup 能够提供以下的几种功能：<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1giefs4o15ij30xc08wmxp.jpg" alt="undefined"></p>
<blockquote>
<p>在 CGroup 中，所有的任务就是一个系统的一个进程，而 CGroup 就是一组按照某种标准划分的进程，在 CGroup 这种机制中，所有的资源控制都是以 CGroup 作为单位实现的，每一个进程都可以随时加入一个 CGroup 也可以随时退出一个 CGroup。<br>  <a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/linux/1506_cgroup/index.html">——CGroup 介绍、应用实例及原理描述</a><br>  <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/b02bf3b3f265">——Docker之Linux Cgroup实践</a></p>
</blockquote>
<p>  Linux 使用文件系统来实现 CGroup，我们可以直接使用下面的命令查看当前的 CGroup 中有哪些子系统：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ lssubsys -m</span><br><span class="line">cpuset &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset</span><br><span class="line">cpu &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu</span><br><span class="line">cpuacct &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuacct</span><br><span class="line">memory &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory</span><br><span class="line">devices &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;devices</span><br><span class="line">freezer &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;freezer</span><br><span class="line">blkio &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;blkio</span><br><span class="line">perf_event &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;perf_event</span><br><span class="line">hugetlb &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;hugetlb</span><br></pre></td></tr></table></figure>

<p>  大多数 Linux 的发行版都有着非常相似的子系统，而之所以将上面的 cpuset、cpu 等东西称作子系统，是因为它们能够为对应的控制组分配资源并限制资源的使用。</p>
<p>  如果我们想要创建一个新的 cgroup 只需要在想要分配或者限制资源的子系统下面创建一个新的文件夹，然后这个文件夹下就会自动出现很多的内容，如果你在 Linux 上安装了 Docker，你就会发现所有子系统的目录下都有一个名为 Docker 的文件夹：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ ls cpu</span><br><span class="line">cgroup.clone_children  </span><br><span class="line">...</span><br><span class="line">cpu.stat  </span><br><span class="line">docker  </span><br><span class="line">notify_on_release </span><br><span class="line">release_agent </span><br><span class="line">tasks</span><br><span class="line"></span><br><span class="line">$ ls cpu&#x2F;docker&#x2F;</span><br><span class="line">9c3057f1291b53fd54a3d12023d2644efe6a7db6ddf330436ae73ac92d401cf1 </span><br><span class="line">cgroup.clone_children  </span><br><span class="line">...</span><br><span class="line">cpu.stat  </span><br><span class="line">notify_on_release </span><br><span class="line">release_agent </span><br><span class="line">tasks</span><br></pre></td></tr></table></figure>

<p>  9c3057xxx 其实就是我们运行的一个 Docker 容器，启动这个容器时，Docker 会为这个容器创建一个与容器标识符相同的 CGroup，在当前的主机上 CGroup 就会有以下的层级关系：<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1giegzlwkecj30xc0hsaam.jpg" alt="undefined"></p>
<p>  每一个 CGroup 下面都有一个 tasks 文件，其中存储着属于当前控制组的所有进程的 pid，作为负责 cpu 的子系统，cpu.cfs_quota_us 文件中的内容能够对 CPU 的使用作出限制，如果当前文件的内容为 50000，那么当前控制组中的全部进程的 CPU 占用率不能超过 50%。</p>
<p>  如果系统管理员想要控制 Docker 某个容器的资源使用率就可以在 docker 这个父控制组下面找到对应的子控制组并且改变它们对应文件的内容，当然我们也可以直接在程序运行时就使用参数，让 Docker 进程去改变相应文件中的内容。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it -d --cpu-quota&#x3D;50000 busybox</span><br><span class="line">53861305258ecdd7f5d2a3240af694aec9adb91cd4c7e210b757f71153cdd274</span><br><span class="line">$ cd 53861305258ecdd7f5d2a3240af694aec9adb91cd4c7e210b757f71153cdd274&#x2F;</span><br><span class="line">$ ls</span><br><span class="line">cgroup.clone_children  cgroup.event_control  cgroup.procs  cpu.cfs_period_us  cpu.cfs_quota_us  cpu.shares  cpu.stat  notify_on_release  tasks</span><br><span class="line">$ cat cpu.cfs_quota_us</span><br><span class="line">50000</span><br></pre></td></tr></table></figure>

<p>  当我们使用 Docker 关闭掉正在运行的容器时，Docker 的子控制组对应的文件夹也会被 Docker 进程移除，Docker 在使用 CGroup 时其实也只是做了一些创建文件夹改变文件内容的文件操作，不过 CGroup 的使用也确实解决了我们限制子容器资源占用的问题，系统管理员能够为多个容器合理的分配资源并且不会出现多个容器互相抢占资源的问题。</p>
</li>
</ul>
<h4 id="UnionFS"><a href="#UnionFS" class="headerlink" title="UnionFS"></a>UnionFS</h4><ul>
<li><p>Linux 的命名空间和控制组分别解决了不同资源隔离的问题，前者解决了进程、网络以及文件系统的隔离，后者实现了 CPU、内存等资源的隔离，但是在 Docker 中还有另一个非常重要的问题需要解决 - 也就是镜像。</p>
<p>  镜像到底是什么，它又是如何组成和组织的是作者使用 Docker 以来的一段时间内一直比较让作者感到困惑的问题，我们可以使用 docker run 非常轻松地从远程下载 Docker 的镜像并在本地运行。</p>
<p>  Docker 镜像其实本质就是一个压缩包，我们可以使用下面的命令将一个 Docker 镜像中的文件导出：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker export $(docker create busybox) | tar -C rootfs -xvf -</span><br><span class="line">$ ls</span><br><span class="line">bin  dev  etc  home proc root sys  tmp  usr  var</span><br></pre></td></tr></table></figure>
<p>  你可以看到这个 busybox 镜像中的目录结构与 Linux 操作系统的根目录中的内容并没有太多的区别，可以说 Docker 镜像就是一个文件。</p>
</li>
</ul>
<h4 id="存储驱动"><a href="#存储驱动" class="headerlink" title="存储驱动"></a>存储驱动</h4><ul>
<li><p>Docker 使用了一系列不同的存储驱动管理镜像内的文件系统并运行容器，这些存储驱动与 Docker 卷（volume）有些不同，存储引擎管理着能够在多个容器之间共享的存储。</p>
<p>  想要理解 Docker 使用的存储驱动，我们首先需要理解 Docker 是如何构建并且存储镜像的，也需要明白 Docker 的镜像是如何被每一个容器所使用的；Docker 中的每一个镜像都是由一系列只读的层组成的，Dockerfile 中的每一个命令都会在已有的只读层上创建一个新的层：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:15.04</span><br><span class="line">COPY . &#x2F;app</span><br><span class="line">RUN make &#x2F;app</span><br><span class="line">CMD python &#x2F;app&#x2F;app.py</span><br></pre></td></tr></table></figure>

<p>  容器中的每一层都只对当前容器进行了非常小的修改，上述的 Dockerfile 文件会构建一个拥有四层 layer 的镜像：<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1giekx0sd0uj30xc0k0752.jpg" alt="undefined"></p>
<p>  当镜像被 docker run 命令创建时就会在镜像的最上层添加一个可写的层，也就是容器层，所有对于运行时容器的修改其实都是对这个容器读写层的修改。</p>
<p>  容器和镜像的区别就在于，所有的镜像都是只读的，而每一个容器其实等于镜像加上一个可读写的层，也就是同一个镜像可以对应多个容器。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1giekxlw934j30xc0dcdg0.jpg" alt="undefined"></p>
</li>
</ul>
<h4 id="AUFS"><a href="#AUFS" class="headerlink" title="AUFS"></a>AUFS</h4><ul>
<li><p>UnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀的性能和效率。</p>
<p>  AUFS 作为联合文件系统，它能够将不同文件夹中的层联合（Union）到了同一个文件夹中，这些文件夹在 AUFS 中称作分支，整个『联合』的过程被称为联合挂载（Union Mount）：<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1gieladoqu9j30xc0lezlr.jpg" alt="undefined"></p>
<p>  每一个镜像层或者容器层都是 /var/lib/docker/ 目录下的一个子文件夹；在 Docker 中，所有镜像层和容器层的内容都存储在 /var/lib/docker/aufs/diff/ 目录中：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ls &#x2F;var&#x2F;lib&#x2F;docker&#x2F;aufs&#x2F;diff&#x2F;00adcccc1a55a36a610a6ebb3e07cc35577f2f5a3b671be3dbc0e74db9ca691c       93604f232a831b22aeb372d5b11af8c8779feb96590a6dc36a80140e38e764d8</span><br><span class="line">00adcccc1a55a36a610a6ebb3e07cc35577f2f5a3b671be3dbc0e74db9ca691c-init  93604f232a831b22aeb372d5b11af8c8779feb96590a6dc36a80140e38e764d8-init</span><br><span class="line">019a8283e2ff6fca8d0a07884c78b41662979f848190f0658813bb6a9a464a90       93b06191602b7934fafc984fbacae02911b579769d0debd89cf2a032e7f35cfa</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>  而 /var/lib/docker/aufs/layers/ 中存储着镜像层的元数据，每一个文件都保存着镜像层的元数据，最后的 /var/lib/docker/aufs/mnt/ 包含镜像或者容器层的挂载点，最终会被 Docker 通过联合的方式进行组装。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1gielbaxvx3j30m80go3z3.jpg" alt="undefined"></p>
<p>  上面的这张图片非常好的展示了组装的过程，每一个镜像层都是建立在另一个镜像层之上的，同时所有的镜像层都是只读的，只有每个容器最顶层的容器层才可以被用户直接读写，所有的容器都建立在一些底层服务（Kernel）上，包括命名空间、控制组、rootfs 等等，这种容器的组装方式提供了非常大的灵活性，只读的镜像层通过共享也能够减少磁盘的占用。</p>
</li>
</ul>
<h4 id="其他存储驱动"><a href="#其他存储驱动" class="headerlink" title="其他存储驱动"></a>其他存储驱动</h4><ul>
<li><p>AUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 还支持了不同的存储驱动，包括 aufs、devicemapper、overlay2、zfs 和 vfs 等等，在最新的 Docker 中，overlay2 取代了 aufs 成为了推荐的存储驱动，但是在没有 overlay2 驱动的机器上仍然会使用 aufs 作为 Docker 的默认驱动。<br>  <img src="http://ww1.sinaimg.cn/large/005Seyywly1gielca7a42j30xc08wjrv.jpg" alt="undefined"></p>
<p>  不同的存储驱动在存储镜像和容器文件时也有着完全不同的实现，有兴趣的读者可以在 Docker 的官方文档 Select a storage driver 中找到相应的内容。</p>
<p>  想要查看当前系统的 Docker 上使用了哪种存储驱动只需要使用以下的命令就能得到相对应的信息：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker info | grep Storage</span><br><span class="line">Storage Driver: aufs</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>Docker 的核心技术其实已经有很多年的历史了，Linux 命名空间、控制组和 UnionFS 三大技术支撑了目前 Docker 的实现，也是 Docker 能够出现的最重要原因。<blockquote>
<p>原文链接：<a target="_blank" rel="noopener" href="https://draveness.me/docker">https://draveness.me/docker</a></p>
</blockquote>
</li>
</ul>
<h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><ul>
<li><h4 id="clone-flag1"><a href="#clone-flag1" class="headerlink" title="clone-flag1"></a>clone-flag1</h4><p>  当调用clone时，设定了CLONE_NEWPID，就会创建一个新的PID Namespace，clone出来的新进程将成为Namespace里的第一个进程。一个PID Namespace为进程提供了一个独立的PID环境，PID Namespace内的PID将从1开始，在Namespace内调用fork，vfork或clone都将产生一个在该Namespace内独立的PID。新创建的Namespace里的第一个进程在该Namespace内的PID将为1，就像一个独立的系统里的init进程一样。该Namespace内的孤儿进程都将以该进程为父进程，当该进程被结束时，该Namespace内所有的进程都会被结束。PID Namespace是层次性，新创建的Namespace将会是创建该Namespace的进程属于的Namespace的子Namespace。子Namespace中的进程对于父Namespace是可见的，一个进程将拥有不止一个PID，而是在所在的Namespace以及所有直系祖先Namespace中都将有一个PID。系统启动时，内核将创建一个默认的PID Namespace，该Namespace是所有以后创建的Namespace的祖先，因此系统所有的进程在该Namespace都是可见的。</p>
</li>
<li><h4 id="clone-flag2"><a href="#clone-flag2" class="headerlink" title="clone-flag2"></a>clone-flag2</h4><p>  当调用clone时，设定了CLONE_NEWIPC，就会创建一个新的IPC Namespace，clone出来的进程将成为Namespace里的第一个进程。一个IPC Namespace有一组System V IPC objects 标识符构成，这标识符有IPC相关的系统调用创建。在一个IPC Namespace里面创建的IPC object对该Namespace内的所有进程可见，但是对其他Namespace不可见，这样就使得不同Namespace之间的进程不能直接通信，就像是在不同的系统里一样。当一个IPC Namespace被销毁，该Namespace内的所有IPC object会被内核自动销毁。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PID Namespace和IPC Namespace可以组合起来一起使用，只需在调用<span class="built_in">clone</span>时，同时指定CLONE_NEWPID和CLONE_NEWIPC，这样新创建的Namespace既是一个独立的PID空间又是一个独立的IPC空间。不同Namespace的进程彼此不可见，也不能互相通信，这样就实现了进程间的隔离。</span><br></pre></td></tr></table></figure>
</li>
<li><h4 id="clone-flag3"><a href="#clone-flag3" class="headerlink" title="clone-flag3"></a>clone-flag3</h4><p>  当调用clone时，设定了CLONE_NEWNS，就会创建一个新的mount Namespace。每个进程都存在于一个mount Namespace里面，mount Namespace为进程提供了一个文件层次视图。如果不设定这个flag，子进程和父进程将共享一个mount Namespace，其后子进程调用mount或umount将会影响到所有该Namespace内的进程。如果子进程在一个独立的mount Namespace里面，就可以调用mount或umount建立一份新的文件层次视图。该flag配合pivot_root系统调用，可以为进程创建一个独立的目录空间。</p>
</li>
<li><h4 id="clone-flag4"><a href="#clone-flag4" class="headerlink" title="clone-flag4"></a>clone-flag4</h4><p>  当调用clone时，设定了CLONE_NEWNET，就会创建一个新的Network Namespace。一个Network Namespace为进程提供了一个完全独立的网络协议栈的视图。包括网络设备接口，IPv4和IPv6协议栈，IP路由表，防火墙规则，sockets等等。一个Network Namespace提供了一份独立的网络环境，就跟一个独立的系统一样。一个物理设备只能存在于一个Network Namespace中，可以从一个Namespace移动另一个Namespace中。虚拟网络设备(virtual network device)提供了一种类似管道的抽象，可以在不同的Namespace之间建立隧道。利用虚拟化网络设备，可以建立到其他Namespace中的物理设备的桥接。当一个Network Namespace被销毁时，物理设备会被自动移回init Network Namespace，即系统最开始的Namespace。</p>
</li>
<li><h4 id="clone-flag5"><a href="#clone-flag5" class="headerlink" title="clone-flag5"></a>clone-flag5</h4><p>  当调用clone时，设定了CLONE_NEWUTS，就会创建一个新的UTS Namespace。一个UTS Namespace就是一组被uname返回的标识符。新的UTS Namespace中的标识符通过复制调用进程所属的Namespace的标识符来初始化。Clone出来的进程可以通过相关系统调用改变这些标识符，比如调用sethostname来改变该Namespace的hostname。这一改变对该Namespace内的所有进程可见。CLONE_NEWUTS和CLONE_NEWNET一起使用，可以虚拟出一个有独立主机名和网络空间的环境，就跟网络上一台独立的主机一样。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以上所有<span class="built_in">clone</span> flag都可以一起使用，为进程提供了一个独立的运行环境。LXC正是通过在<span class="built_in">clone</span>时设定这些flag，为进程创建一个有独立PID，IPC，FS，Network，UTS空间的container。一个container就是一个虚拟的运行环境，对container里的进程是透明的，它会以为自己是直接在一个系统上运行的。一个container就像传统虚拟化技术里面的一台安装了OS的虚拟机，但是开销更小，部署更为便捷。</span><br></pre></td></tr></table></figure>
</li>
<li><h4 id="sbin-init"><a href="#sbin-init" class="headerlink" title="sbin-init"></a>sbin-init</h4><p>  Linux内核加载启动后，用户空间的第一个进程就是初始化进程，这个程序的物理文件约定位于/sbin/init，当然也可以通过传递内核参数来让内核启动指定的程序。这个进程的特点是进程号为1，代表第一个运行的用户空间进程。不同发行版采用了不同的启动程序，主要有以下几种主流选择：</p>
<pre><code>  以 Ubuntu 为代表的 Linux 发行版采用 upstart
  CentOS7.0 版本之前的 System V init
  CentOS7.0 版本的 systemd</code></pre>
</li>
<li><h4 id="kthreadd"><a href="#kthreadd" class="headerlink" title="kthreadd"></a>kthreadd</h4><p>  这种内核线程只有一个，它的作用是管理调度其它的内核线程。这个线程不能关闭。它在内核初始化的时候被创建，会循环运行一个叫做kthreadd的函数，该函数的作用是运行kthread_create_list全局链表中维护的kthread。其他任务或代码想创建内核线程时需要调用kthread_create（或kthread_create_on_node）创建一个kthread，该kthread会被加入到kthread_create_list链表中，同时kthread_create会weak up kthreadd_task（即kthreadd）（增链表）。kthreadd再执行kthread时会调用老的接口——kernel_thread运行一个名叫“kthread”的内核线程去运行创建的kthread，被执行过的kthread会从kthread_create_list链表中删除（减链表），并且kthreadd会不断调用scheduler 让出CPU。kthreadd创建的kthread执行完后，会调到kthread_create()执行，之后再执行最初原任务或代码。</p>
</li>
<li><h4 id="idle"><a href="#idle" class="headerlink" title="idle"></a>idle</h4><p>  简单的说idle是一个进程，其pid号为 0。其前身是系统创建的第一个进程，也是唯一一个没有通过fork()产生的进程。在smp系统中，每个处理器单元有独立的一个运行队列，而每个运行队列上又有一个idle进程，即有多少处理器单元，就有多少idle进程。系统的空闲时间，其实就是指idle进程的”运行时间”。</p>
</li>
<li><h4 id="getty"><a href="#getty" class="headerlink" title="getty"></a>getty</h4><p>  是Unix类操作系统启动时必须的三个步骤之一，用来开启终端，进行终端的初始化，设置终端。</p>
</li>
<li><h4 id="chroot"><a href="#chroot" class="headerlink" title="chroot"></a>chroot</h4><p>  在这里不得不简单介绍一下 chroot（change root），在 Linux 系统中，系统默认的目录就都是以 / 也就是根目录开头的，chroot 的使用能够改变当前的系统根目录结构，通过改变当前系统的根目录，我们能够限制用户的权利，在新的根目录下并不能够访问旧系统根目录的结构个文件，也就建立了一个与原系统完全隔离的目录结构。</p>
<blockquote>
<p>与 chroot 的相关内容部分来自<a target="_blank" rel="noopener" href="https://developer.ibm.com/zh/technologies/linux/">《理解 chroot》</a>一文，各位读者可以阅读这篇文章获得更详细的信息。</p>
</blockquote>
</li>
</ul>

                    
                    <!-- Tags Bottom -->
                    
                        <div class="tags-container-bottom">
                            <i class="fa fa-tag pr3 text-main-color"></i><a class="fw3 ph1 dib" href="/tags/docker/">#docker</a> <a class="fw3 ph1 dib" href="/tags/虚拟机/">#虚拟机</a>
                        </div>
                    

                    <!-- Comments -->
                    



                </div>
                <div class="fl w-100 w-30-l center fw3 lh-copy pl4-ns tl black-50">
                    
                    <hr class="dn-l mw4 black-50 mt5" />
                    
                    <!-- Widget 1: About -->
                    <div class="mt5 mt0-l">
    <article class="dt db-l mw8 mw8-m mw5-ns center ml0-l bg-white mv3">
        <div class="dn dtc-m db-l v-mid tc pr4 pr0-l" style="min-width: 6rem;">
            <img src="http://ww1.sinaimg.cn/large/005Seyywly1gib8wvfkkej31400u0q4x.jpg" class="mb4-l br-100 h3 w3 h4-l w4-l dib" title="yhb">
        </div>
        <div class="dtc db-l v-mid lh-copy measure center f6 black-50 tj">
            My name is yhb and this is my blog.<br>I am a full stack software engineer with a strong rear-end focus.<br> I currently live and work in beijing.
        </div>
    </article>
</div>

                    <hr class="dn-l mw4 black-50 mt5" />
                    
                    <!-- Widget 2: Categories -->
                    

                    <!-- Widget 3: Recent Posts -->
                    <div class="mt5 tc tl-l">
    <h3>Recent Posts</h3>
    
        <p>
            <a href="/2020/11/26/ab%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/">ab压测工具使用</a>
        </p>
    
        <p>
            <a href="/2020/11/26/%E5%8F%98%E9%87%8F-%E5%87%BD%E6%95%B0-%E7%B1%BB%E7%9A%84%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99/">变量、函数、类的命名规则</a>
        </p>
    
        <p>
            <a href="/2020/11/23/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/">前端学习手册</a>
        </p>
    
        <p>
            <a href="/2020/11/04/MariaDB%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85/">MariaDB数据库安装</a>
        </p>
    
        <p>
            <a href="/2020/09/07/python-23%E7%A7%8D%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%92%8C%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B/">python 23种常用设计模式和代码示例</a>
        </p>
    
</div>
                </div>
            </div>
        </div>
    </div>
</div>


<!-- Footer -->
<div class="bg-1 ph2 ph5-ns pv5">
        <div class="mv8">
            <div class="center tc">
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://twitter.com/?lang=en" target="_blank">
                            <i class="fa fa-twitter"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://www.facebook.com/" target="_blank">
                            <i class="fa fa-facebook"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://dribbble.com/" target="_blank">
                            <i class="fa fa-dribbble"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://github.com/klugjo/hexo-theme-anodyne" target="_blank">
                            <i class="fa fa-github"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://plus.google.com/" target="_blank">
                            <i class="fa fa-google-plus"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://www.behance.net/" target="_blank">
                            <i class="fa fa-behance"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="https://500px.com/" target="_blank">
                            <i class="fa fa-500px"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="mailto:test@example.com" target="_blank">
                            <i class="fa fa-envelope"></i>
                        </a>
                    </div>
                
                    <div class="dib mh3">
                        <a class="f3 f2-ns white dim" href="/#" target="_blank">
                            <i class="fa fa-rss"></i>
                        </a>
                    </div>
                
            </div>
            <div class="f6 f5-ns center tc white pt5 fw3">
                @Untitled. All right reserved | Design & Hexo <a class="link dim white" target="_blank" rel="noopener" href="http://www.codeblocq.com/">Jonathan Klughertz</a>
            </div>
        </div>
    </div>

<!-- After Footer -->
<!-- Disqus Comments -->



</body>

</html>